{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9678009,"sourceType":"datasetVersion","datasetId":5915180}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install torcheval","metadata":{"execution":{"iopub.status.busy":"2024-10-20T22:12:37.395786Z","iopub.execute_input":"2024-10-20T22:12:37.396664Z","iopub.status.idle":"2024-10-20T22:12:50.229930Z","shell.execute_reply.started":"2024-10-20T22:12:37.396622Z","shell.execute_reply":"2024-10-20T22:12:50.228747Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting torcheval\n  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torcheval) (4.12.2)\nDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torcheval\nSuccessfully installed torcheval-0.0.7\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install iterative-stratification","metadata":{"execution":{"iopub.status.busy":"2024-10-20T22:12:50.231742Z","iopub.execute_input":"2024-10-20T22:12:50.232103Z","iopub.status.idle":"2024-10-20T22:13:02.057776Z","shell.execute_reply.started":"2024-10-20T22:12:50.232067Z","shell.execute_reply":"2024-10-20T22:13:02.056376Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting iterative-stratification\n  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from iterative-stratification) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from iterative-stratification) (1.14.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from iterative-stratification) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->iterative-stratification) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->iterative-stratification) (3.5.0)\nDownloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\nInstalling collected packages: iterative-stratification\nSuccessfully installed iterative-stratification-0.1.9\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# pip install torch==2.4.1 #+cu121","metadata":{"execution":{"iopub.status.busy":"2024-10-20T22:13:02.059359Z","iopub.execute_input":"2024-10-20T22:13:02.059764Z","iopub.status.idle":"2024-10-20T22:13:02.064940Z","shell.execute_reply.started":"2024-10-20T22:13:02.059716Z","shell.execute_reply":"2024-10-20T22:13:02.063716Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# pip install xgboost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:13:02.067661Z","iopub.execute_input":"2024-10-20T22:13:02.068438Z","iopub.status.idle":"2024-10-20T22:13:02.076694Z","shell.execute_reply.started":"2024-10-20T22:13:02.068402Z","shell.execute_reply":"2024-10-20T22:13:02.075704Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# pip install catboost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:13:02.078188Z","iopub.execute_input":"2024-10-20T22:13:02.078535Z","iopub.status.idle":"2024-10-20T22:13:02.088235Z","shell.execute_reply.started":"2024-10-20T22:13:02.078503Z","shell.execute_reply":"2024-10-20T22:13:02.087330Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# pip install lightgbm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:13:02.089958Z","iopub.execute_input":"2024-10-20T22:13:02.090347Z","iopub.status.idle":"2024-10-20T22:13:02.098555Z","shell.execute_reply.started":"2024-10-20T22:13:02.090290Z","shell.execute_reply":"2024-10-20T22:13:02.097547Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# from google.colab import drive\nimport pandas as pd\nimport numpy as np\nimport re\nimport time\nimport gc\nfrom tqdm.notebook import tqdm\nfrom collections import Counter\nimport os\nimport random\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torcheval.metrics.functional import multiclass_f1_score\nfrom torcheval.metrics import MulticlassF1Score\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport torch.optim as optim\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom torcheval.metrics.functional import multiclass_f1_score\nfrom sklearn.decomposition import PCA\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import f1_score\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.utils.validation import check_random_state","metadata":{"id":"ybIns19S5V3l","execution":{"iopub.status.busy":"2024-10-20T22:13:02.099880Z","iopub.execute_input":"2024-10-20T22:13:02.100258Z","iopub.status.idle":"2024-10-20T22:13:13.568091Z","shell.execute_reply.started":"2024-10-20T22:13:02.100214Z","shell.execute_reply":"2024-10-20T22:13:13.567328Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# drive.mount('./drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uKQYPqcm6onr","outputId":"8215a516-fcef-4d69-c943-4f321b4806be","execution":{"iopub.status.busy":"2024-10-20T22:13:13.569598Z","iopub.execute_input":"2024-10-20T22:13:13.570343Z","iopub.status.idle":"2024-10-20T22:13:13.574421Z","shell.execute_reply.started":"2024-10-20T22:13:13.570269Z","shell.execute_reply":"2024-10-20T22:13:13.573514Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"dataset_dir = '/kaggle/input/lifedatabase/'\n\n# train = pd.read_csv(dataset_dir+'train.csv')\n# test = pd.read_csv(dataset_dir+'test.csv')\n# sample_submission = pd.read_csv('/kaggle/input/lifedata/sample_submission.csv')\ntrain = pd.read_csv('/kaggle/input/lifedata/train_middle_course.csv')\ntest_data = pd.read_csv('/kaggle/input/lifedata/test_middle_course.csv')","metadata":{"id":"Ed5tw4uw6xum","execution":{"iopub.status.busy":"2024-10-20T22:13:13.575671Z","iopub.execute_input":"2024-10-20T22:13:13.575959Z","iopub.status.idle":"2024-10-20T22:13:24.642744Z","shell.execute_reply.started":"2024-10-20T22:13:13.575927Z","shell.execute_reply":"2024-10-20T22:13:24.641678Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:13:24.647074Z","iopub.execute_input":"2024-10-20T22:13:24.647945Z","iopub.status.idle":"2024-10-20T22:13:24.652348Z","shell.execute_reply.started":"2024-10-20T22:13:24.647895Z","shell.execute_reply":"2024-10-20T22:13:24.651503Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"CFG = {\n    'SEED': 42\n}\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    check_random_state(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(CFG['SEED']) # Seed 고정\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T22:13:24.653555Z","iopub.execute_input":"2024-10-20T22:13:24.653864Z","iopub.status.idle":"2024-10-20T22:13:24.707381Z","shell.execute_reply.started":"2024-10-20T22:13:24.653831Z","shell.execute_reply":"2024-10-20T22:13:24.706495Z"},"trusted":true},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# EDA","metadata":{"id":"pwgSxQ6yCDlb"}},{"cell_type":"code","source":"parts = []\nfor i in range(4):\n     # , map_location=device\n  part = torch.load(f'/kaggle/input/lifedata/train_padded_sequences{i+1}.pt').to(torch.float16)\n  parts.append(part)\n  del part\n  gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-10-20T22:13:24.708409Z","iopub.execute_input":"2024-10-20T22:13:24.708686Z","iopub.status.idle":"2024-10-20T22:14:08.188113Z","shell.execute_reply.started":"2024-10-20T22:13:24.708655Z","shell.execute_reply":"2024-10-20T22:14:08.187336Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/54422879.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  part = torch.load(f'/kaggle/input/lifedata/train_padded_sequences{i+1}.pt').to(torch.float16)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"train_padded_sequences = torch.cat(parts, dim = 1)\n\ndel parts\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-10-20T22:14:08.189367Z","iopub.execute_input":"2024-10-20T22:14:08.189680Z","iopub.status.idle":"2024-10-20T22:14:10.325381Z","shell.execute_reply.started":"2024-10-20T22:14:08.189647Z","shell.execute_reply":"2024-10-20T22:14:10.324462Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"parts = []\nfor i in range(4):\n     # , map_location=device\n  part = torch.load(f'/kaggle/input/lifedata/test_padded_sequences{i+1}.pt').to(torch.float16)\n  parts.append(part)\n  del part\n  gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:14:10.326884Z","iopub.execute_input":"2024-10-20T22:14:10.327435Z","iopub.status.idle":"2024-10-20T22:14:10.331691Z","shell.execute_reply.started":"2024-10-20T22:14:10.327390Z","shell.execute_reply":"2024-10-20T22:14:10.330647Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"test_padded_sequences = torch.cat(parts, dim = 1)\n\ndel parts\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:00:20.546197Z","iopub.status.idle":"2024-10-20T22:00:20.546568Z","shell.execute_reply.started":"2024-10-20T22:00:20.546391Z","shell.execute_reply":"2024-10-20T22:00:20.546409Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(train_padded_sequences, 'train_padded_sequences_full.pt')\ntorch.save(test_padded_sequences, 'test_padded_sequences_full.pt')","metadata":{"execution":{"iopub.status.busy":"2024-10-20T22:00:20.547519Z","iopub.status.idle":"2024-10-20T22:00:20.547878Z","shell.execute_reply.started":"2024-10-20T22:00:20.547702Z","shell.execute_reply":"2024-10-20T22:00:20.547720Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_padded_sequences.shape#, test_padded_sequences.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-20T22:14:10.332827Z","iopub.execute_input":"2024-10-20T22:14:10.333104Z","iopub.status.idle":"2024-10-20T22:14:10.343430Z","shell.execute_reply.started":"2024-10-20T22:14:10.333075Z","shell.execute_reply":"2024-10-20T22:14:10.342631Z"},"trusted":true},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"torch.Size([6201, 4227, 95])"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# labels = torch.tensor(train['SUBCLASS'].values, dtype=torch.long)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T22:14:10.344469Z","iopub.execute_input":"2024-10-20T22:14:10.344733Z","iopub.status.idle":"2024-10-20T22:14:10.350952Z","shell.execute_reply.started":"2024-10-20T22:14:10.344692Z","shell.execute_reply":"2024-10-20T22:14:10.350166Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# labels.unique() # 26 classes","metadata":{"execution":{"iopub.status.busy":"2024-10-20T22:14:10.352156Z","iopub.execute_input":"2024-10-20T22:14:10.352873Z","iopub.status.idle":"2024-10-20T22:14:10.360436Z","shell.execute_reply.started":"2024-10-20T22:14:10.352842Z","shell.execute_reply":"2024-10-20T22:14:10.359457Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"one_hot_encoder = OneHotEncoder(sparse = False) # sparse = False\nlabels_one_hot = one_hot_encoder.fit_transform(labels.reshape(-1, 1))","metadata":{"execution":{"iopub.status.busy":"2024-10-20T22:14:10.388017Z","iopub.execute_input":"2024-10-20T22:14:10.388281Z","iopub.status.idle":"2024-10-20T22:14:10.406236Z","shell.execute_reply.started":"2024-10-20T22:14:10.388251Z","shell.execute_reply":"2024-10-20T22:14:10.405422Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"train['SUBCLASS']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:03:44.296834Z","iopub.execute_input":"2024-10-20T22:03:44.297245Z","iopub.status.idle":"2024-10-20T22:03:44.306404Z","shell.execute_reply.started":"2024-10-20T22:03:44.297206Z","shell.execute_reply":"2024-10-20T22:03:44.304693Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"0        KIPAN\n1         SARC\n2         SKCM\n3         KIRC\n4       GBMLGG\n         ...  \n6196      LUAD\n6197       LGG\n6198      COAD\n6199      TGCT\n6200      SKCM\nName: SUBCLASS, Length: 6201, dtype: object"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"le_encoder = LabelEncoder()\nlabels = le_encoder.fit_transform(train['SUBCLASS'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:14:10.361589Z","iopub.execute_input":"2024-10-20T22:14:10.362190Z","iopub.status.idle":"2024-10-20T22:14:10.376133Z","shell.execute_reply.started":"2024-10-20T22:14:10.362148Z","shell.execute_reply":"2024-10-20T22:14:10.375339Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:14:10.377324Z","iopub.execute_input":"2024-10-20T22:14:10.377690Z","iopub.status.idle":"2024-10-20T22:14:10.386961Z","shell.execute_reply.started":"2024-10-20T22:14:10.377649Z","shell.execute_reply":"2024-10-20T22:14:10.386050Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"array([ 8, 19, 20, ...,  4, 22, 20])"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# flattened_data = train_padded_sequences.view(train_padded_sequences.size(0), -1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:00:20.562006Z","iopub.status.idle":"2024-10-20T22:00:20.562375Z","shell.execute_reply.started":"2024-10-20T22:00:20.562203Z","shell.execute_reply":"2024-10-20T22:00:20.562221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# labels = np.argmax(labels_one_hot, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:00:20.563519Z","iopub.status.idle":"2024-10-20T22:00:20.563841Z","shell.execute_reply.started":"2024-10-20T22:00:20.563675Z","shell.execute_reply":"2024-10-20T22:00:20.563691Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# flattened_data.shape, labels.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:00:20.565185Z","iopub.status.idle":"2024-10-20T22:00:20.565533Z","shell.execute_reply.started":"2024-10-20T22:00:20.565359Z","shell.execute_reply":"2024-10-20T22:00:20.565377Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EmbeddingFeatureExtraction(nn.Module):\n    def __init__(self, vocab_size, embedding_size, padding_idx=0):\n        super(EmbeddingFeatureExtraction, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=padding_idx)\n\n    def forward(self, x):\n        batch_size, feature_dim, sequence_length = x.size()\n        x = x.reshape(-1, sequence_length).long()\n        x = self.embedding(x)\n        x = x.view(batch_size, feature_dim * sequence_length, -1)\n        return x\n\nclass ConvolutionFeatureExtraction(nn.Module):\n    def __init__(self, num_filters = 64, kernel_size = 5, pooling_size = 2):\n        super(ConvolutionFeatureExtraction, self).__init__()\n        self.conv = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(kernel_size, 95), padding=(1, 0))\n        self.pool = nn.MaxPool2d(kernel_size=(pooling_size, 1))\n        self.dropout = nn.Dropout(0.5)\n        self.bn1 = nn.BatchNorm2d(num_filters)\n        \n    def forward(self, x):\n        batch_size, feature_dim, sequence_length = x.size()\n        x = x.unsqueeze(1).float()\n        x = F.tanh(self.conv(x))\n        # x = self.bn1(x)\n        x = self.pool(x).squeeze(3)\n        # x = self.dropout(x)\n        x = x.view(batch_size, -1)\n        return x\n\n# class ConvolutionFeatureExtraction(nn.Module):\n#     def __init__(self, num_filters = 64, kernel_size = 3, pooling_size = 2):\n#         super(ConvolutionFeatureExtraction, self).__init__()\n#         self.conv = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(kernel_size, 162), padding=(1, 0))\n#         self.pool = nn.MaxPool2d(kernel_size=(pooling_size, 1))\n#         self.dropout = nn.Dropout(0.5)\n#         self.bn1 = nn.BatchNorm2d(num_filters)\n        \n#     def forward(self, x):\n#         batch_size, feature_dim, sequence_length = x.size()\n#         x = x.unsqueeze(1).float()\n#         mask = (x != 0).float()\n#         x_conv = self.conv(x)\n        \n#         x_masked = x_conv * mask\n        \n#         # x_pooled = self.pool(x_masked).squeeze(3)\n        \n#         x_final = x_masked.view(batch_size, -1)\n#         return x_final\n\n# class ConvolutionFeatureExtraction(nn.Module):\n#     def __init__(self, num_filters=64, kernel_size=3):\n#         super(ConvolutionFeatureExtraction, self).__init__()\n#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(kernel_size, 126), padding=(1, 0))\n#         self.pool = nn.MaxPool2d(kernel_size=(2, 1))\n#         self.conv2 = nn.Conv2d(in_channels=num_filters, out_channels=num_filters * 2, kernel_size=(kernel_size, 1), padding=(1, 0))\n#         self.conv3 = nn.Conv2d(in_channels=num_filters * 2, out_channels=num_filters * 4, kernel_size=(kernel_size, 1), padding=(1, 0))\n#         self.dropout = nn.Dropout(0.5)\n    \n#     def forward(self, x):\n#         batch_size, feature_dim, sequence_length = x.size()\n#         x = x.unsqueeze(1)\n#         x = x.float()\n\n#         x = F.relu(self.conv1(x))\n#         x = self.pool(x)\n#         x = F.relu(self.conv2(x))\n#         x = self.pool(x)\n#         x = F.relu(self.conv3(x))\n#         x = self.pool(x)\n\n#         x = self.dropout(x)\n        \n#         x = x.view(batch_size, -1)\n#         return x\n\n# class CNN_RNN_Model(nn.Module):\n#     def __init__(self, num_filters = 64, kernel_size = 3, pooling_size = 2, hidden_dim = 128, output_dim = 26, num_layers = 1, dropout = 0.5):\n#         super(CNN_RNN_Model, self).__init__()\n#         self.conv = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(kernel_size, 126), padding=(1, 0))\n#         # self.pool = nn.MaxPool2d(kernel_size=(pooling_size, 1))\n#         self.rnn = nn.RNN(input_size=37, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n#         self.dropout = nn.Dropout(dropout)\n#         self.fc = nn.Linear(hidden_dim, output_dim)\n\n#     def forward(self, x):\n#         batch_size, feature_dim, sequence_length = x.size()\n\n#         x = x.unsqueeze(1)\n#         x = x.float()\n\n#         x = F.relu(self.conv(x))\n#         # x = self.pool(x)\n#         print(x.shape)\n        \n#         # x = x.squeeze(3)\n#         x = x.view(batch_size, -1, x.size(3))\n#         # height, width = x.shape[2], x.shape[3]\n#         # x = x.view(batch_size, width, -1)\n#         print(x.shape)\n#         # x = x.permute(0, 2, 1)\n#         # print(x.shape)\n#         # x = x.view(batch_size, sequence_length, -1)\n\n#         output, hidden = self.rnn(x)\n        \n#         x = output[:, -1, :]\n#         x = self.dropout(x)\n#         x = self.fc(x) \n#         return x\n\n# class CNN_RNN_Model(nn.Module):\n#     def __init__(self, num_filters=64, hidden_dim=128, output_dim=26, num_layers=1, dropout=0.5):\n#         super(CNN_RNN_Model, self).__init__()\n        \n#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(3, 126), padding=(1, 0))\n#         self.pool1 = nn.MaxPool2d(kernel_size = (2, 1))\n#         self.conv2 = nn.Conv2d(in_channels=num_filters, out_channels=num_filters * 2, kernel_size=(3, 64), padding=(1, 0))\n#         self.pool2 = nn.MaxPool2d(kernel_size = (2, 1))\n#         self.conv3 = nn.Conv2d(in_channels=num_filters * 2, out_channels=num_filters * 4, kernel_size=(3, 32), padding=(1, 0))\n#         self.pool3 = nn.MaxPool2d(kernel_size = (2, 1))\n\n#         self.rnn = nn.RNN(input_size=num_filters * 4, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n#         self.dropout = nn.Dropout(dropout)\n#         self.fc = nn.Linear(hidden_dim, output_dim)\n\n#     def forward(self, x):\n#         batch_size, feature_dim, sequence_length = x.size()\n        \n#         x = x.unsqueeze(1)\n#         x = x.float()\n\n#         x = F.relu(self.conv1(x))\n#         x = self.pool1(x)\n#         x = F.relu(self.conv2(x))\n#         x = self.pool2(x)\n#         x = F.relu(self.conv3(x))\n#         x = self.pool3(x)\n\n#         x = x.squeeze(3).permute(0, 2, 1)\n\n#         output, hidden = self.rnn(x)\n\n#         x = output[:, -1, :]\n#         x = self.dropout(x)\n#         x = self.fc(x)\n#         # x = F.softmax(x, dim=1)\n        \n#         return x\n\n# class ConvolutionFeatureExtraction(nn.Module):\n#     def __init__(self, num_filters=64, feature_dim=162, kernel_size=3):\n#         super(ConvolutionFeatureExtraction, self).__init__()\n        \n#         self.conv1 = nn.Conv1d(in_channels=feature_dim, out_channels=num_filters, kernel_size=kernel_size, padding=1)\n#         self.pool = nn.MaxPool1d(kernel_size=2)\n        \n#         self.conv2 = nn.Conv1d(in_channels=num_filters, out_channels=num_filters * 2, kernel_size=kernel_size, padding=1)\n        \n#         self.conv3 = nn.Conv1d(in_channels=num_filters * 2, out_channels=num_filters * 4, kernel_size=kernel_size, padding=1)\n        \n#         self.dropout = nn.Dropout(0.5)\n#     def forward(self, x):\n#         batch_size, feature_dim, sequence_length = x.size()\n        \n#         x = x.view(batch_size, sequence_length, feature_dim)\n        \n#         x = x.float()\n\n#         x = F.relu(self.conv1(x))\n#         x = self.pool(x)\n        \n#         x = F.relu(self.conv2(x))\n#         x = self.pool(x)\n        \n#         x = F.relu(self.conv3(x))\n#         x = self.pool(x)\n\n#         x = self.dropout(x)\n        \n#         x = x.view(batch_size, -1)\n#         return x\n\nclass RNN(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, dropout, hidden_dim, output_dim):\n        super().__init__()\n        # self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = 0)\n        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n\n        x.permute(0, 2, 1)\n\n        batch_size, sequence_length, column_length = x.size()\n        \n        # x = self.embedding(x.view(-1, column_length).long())\n\n        x = x.view(batch_size, sequence_length, -1)\n        \n        output, hidden = self.rnn(x)\n\n        x = output[:, -1, :]\n\n        x = self.dropout(x)\n\n        x = self.fc(x)\n\n        # x = F.softmax(x, dim=1)\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:14:10.407620Z","iopub.execute_input":"2024-10-20T22:14:10.407901Z","iopub.status.idle":"2024-10-20T22:14:10.426990Z","shell.execute_reply.started":"2024-10-20T22:14:10.407870Z","shell.execute_reply":"2024-10-20T22:14:10.426178Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"class ConvGRUCell(nn.Module):\n    def __init__(self, input_channels, hidden_channels, kernel_size):\n        super(ConvGRUCell, self).__init__()\n        self.hidden_channels = hidden_channels\n        self.update_gate = nn.Conv2d(in_channels=input_channels + hidden_channels, out_channels=hidden_channels, kernel_size=kernel_size, padding=(kernel_size[0] // 2, kernel_size[1] // 2))\n        self.reset_gate = nn.Conv2d(in_channels=input_channels + hidden_channels, out_channels=hidden_channels, kernel_size=kernel_size, padding=(kernel_size[0] // 2, kernel_size[1] // 2))\n        self.out_gate = nn.Conv2d(in_channels=input_channels + hidden_channels, out_channels=hidden_channels, kernel_size=kernel_size, padding=(kernel_size[0] // 2, kernel_size[1] // 2))\n\n    def forward(self, x, hidden_state):\n        combined = torch.cat([x, hidden_state], dim=1)\n        update = torch.sigmoid(self.update_gate(combined))\n        reset = torch.sigmoid(self.reset_gate(combined))\n        new_hidden = torch.tanh(self.out_gate(combined) + reset * hidden_state)\n        hidden_state = update * hidden_state + (1 - update) * new_hidden\n        return hidden_state\n\nclass ConvolutionFeatureExtraction(nn.Module):\n    def __init__(self, num_filters=64, kernel_size=(3, 3), pooling_size=2, hidden_channels=32):\n        super(ConvolutionFeatureExtraction, self).__init__()\n        \n        self.conv = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(kernel_size[0], 162), padding=(kernel_size[0] // 2, 0))\n        self.pool = nn.MaxPool2d(kernel_size=(pooling_size, 1))\n        self.dropout = nn.Dropout(0.5)\n        self.conv_gru = ConvGRUCell(input_channels=num_filters, hidden_channels=hidden_channels, kernel_size=kernel_size)\n\n    def forward(self, x):\n        batch_size, feature_dim, sequence_length = x.size()\n        \n        x = x.unsqueeze(1)\n        x = x.float()\n\n        x = F.relu(self.conv(x))\n        x = self.pool(x)\n\n        x = self.dropout(x)\n\n        hidden_state = torch.zeros(batch_size, self.conv_gru.hidden_channels, x.size(2), x.size(3), device=x.device)\n\n        for t in range(x.size(3)):\n            hidden_state = self.conv_gru(x[:, :, :, t].unsqueeze(3), hidden_state)\n\n        return hidden_state.view(batch_size, -1)\n\nclass ConvGRUCell(nn.Module):\n    def __init__(self, input_channels, hidden_channels, kernel_size):\n        super(ConvGRUCell, self).__init__()\n        self.hidden_channels = hidden_channels\n        self.update_gate = nn.Conv2d(in_channels=input_channels + hidden_channels, out_channels=hidden_channels, kernel_size=kernel_size, padding=(kernel_size[0] // 2, kernel_size[1] // 2))\n        self.reset_gate = nn.Conv2d(in_channels=input_channels + hidden_channels, out_channels=hidden_channels, kernel_size=kernel_size, padding=(kernel_size[0] // 2, kernel_size[1] // 2))\n        self.out_gate = nn.Conv2d(in_channels=input_channels + hidden_channels, out_channels=hidden_channels, kernel_size=kernel_size, padding=(kernel_size[0] // 2, kernel_size[1] // 2))\n\n    def forward(self, x, hidden_state):\n        combined = torch.cat([x, hidden_state], dim=1)\n        update = torch.sigmoid(self.update_gate(combined))\n        reset = torch.sigmoid(self.reset_gate(combined))\n        new_hidden = torch.tanh(self.out_gate(combined) + reset * hidden_state)\n        hidden_state = update * hidden_state + (1 - update) * new_hidden\n        return hidden_state\n\nclass ConvolutionFeatureExtraction(nn.Module):\n    def __init__(self, num_filters=64, kernel_size=(3, 3), pooling_size=2, hidden_channels=32):\n        super(ConvolutionFeatureExtraction, self).__init__()\n        \n        self.conv = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(kernel_size[0], 162), padding=(kernel_size[0] // 2, 0))\n        self.pool = nn.MaxPool2d(kernel_size=(pooling_size, 1))\n        self.dropout = nn.Dropout(0.5)\n        self.conv_gru = ConvGRUCell(input_channels=num_filters, hidden_channels=hidden_channels, kernel_size=kernel_size)\n\n        # Batch Normalization\n        self.bn1 = nn.BatchNorm2d(num_filters)\n        self.bn2 = nn.BatchNorm2d(hidden_channels)\n\n    def forward(self, x):\n        batch_size, feature_dim, sequence_length = x.size()\n        \n        x = x.unsqueeze(1)\n        x = x.float()\n\n        # Convolution layer with Batch Norm\n        x = F.relu(self.bn1(self.conv(x)))\n        x = self.pool(x)\n        x = self.dropout(x)\n\n        # Initialize hidden state for GRU\n        hidden_state = torch.zeros(batch_size, self.conv_gru.hidden_channels, x.size(2), x.size(3), device=x.device)\n\n        # GRU with Batch Norm\n        for t in range(x.size(3)):\n            hidden_state = self.conv_gru(x[:, :, :, t].unsqueeze(3), hidden_state)\n\n        # Apply Batch Norm to hidden state\n        hidden_state = self.bn2(hidden_state)\n\n        return hidden_state.view(batch_size, -1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:04:31.855126Z","iopub.execute_input":"2024-10-20T22:04:31.855497Z","iopub.status.idle":"2024-10-20T22:04:31.881499Z","shell.execute_reply.started":"2024-10-20T22:04:31.855460Z","shell.execute_reply":"2024-10-20T22:04:31.880502Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"train_padded_sequences.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:04:32.362869Z","iopub.execute_input":"2024-10-20T22:04:32.363912Z","iopub.status.idle":"2024-10-20T22:04:32.369555Z","shell.execute_reply.started":"2024-10-20T22:04:32.363869Z","shell.execute_reply":"2024-10-20T22:04:32.368637Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"torch.Size([6201, 4227, 95])"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"test_padded_sequences.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:14:10.428065Z","iopub.execute_input":"2024-10-20T22:14:10.428431Z","iopub.status.idle":"2024-10-20T22:14:10.439544Z","shell.execute_reply.started":"2024-10-20T22:14:10.428388Z","shell.execute_reply":"2024-10-20T22:14:10.438594Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"4230/6","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:04:39.356034Z","iopub.execute_input":"2024-10-20T22:04:39.356435Z","iopub.status.idle":"2024-10-20T22:04:39.362440Z","shell.execute_reply.started":"2024-10-20T22:04:39.356396Z","shell.execute_reply":"2024-10-20T22:04:39.361503Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"705.0"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"batch_size = 64\nvocab_size = 28\nembedding_dim = 128\nnum_filters = 64\nkernel_size = 5\npooling_size = 2\n\n# model = EmbeddingFeatureExtraction(vocab_size, embedding_dim).to('cuda')\nmodel = ConvolutionFeatureExtraction(num_filters = num_filters, kernel_size = kernel_size, pooling_size = pooling_size).to('cuda')\n\ndataset = TensorDataset(train_padded_sequences)\ndata_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n\nembedded_sequences = []\n\nwith torch.no_grad():\n    for batch in data_loader:\n        batch = batch[0].to('cuda')\n\n        batch_embedded = model(batch)\n\n        embedded_sequences.append(batch_embedded)\n\n        del batch, batch_embedded\n        gc.collect()\n        #torch.cuda.empty_cache()\n\nembedded_sequences = torch.cat(embedded_sequences, dim=0)\n\n# test_dataset = TensorDataset(test_padded_sequences)\n# test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n\n# test_embedded_sequences = []\n\n# with torch.no_grad():\n#     for batch in test_data_loader:\n#         batch = batch[0].to('cuda')\n\n#         batch_embedded = model(batch)\n\n#         test_embedded_sequences.append(batch_embedded)\n\n#         del batch, batch_embedded\n#         gc.collect()\n#         #torch.cuda.empty_cache()\n\n# test_embedded_sequences = torch.cat(test_embedded_sequences, dim=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:14:10.443892Z","iopub.execute_input":"2024-10-20T22:14:10.444256Z","iopub.status.idle":"2024-10-20T22:14:31.095176Z","shell.execute_reply.started":"2024-10-20T22:14:10.444224Z","shell.execute_reply":"2024-10-20T22:14:31.094255Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"embedded_sequences.shape#, test_embedded_sequences.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:14:31.096504Z","iopub.execute_input":"2024-10-20T22:14:31.096832Z","iopub.status.idle":"2024-10-20T22:14:31.103355Z","shell.execute_reply.started":"2024-10-20T22:14:31.096795Z","shell.execute_reply":"2024-10-20T22:14:31.102530Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"torch.Size([6201, 135168])"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"data = embedded_sequences.cpu().numpy()\n# test_data = test_embedded_sequences.cpu().numpy()\n\n# data = train_padded_sequences.view(874, -1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:14:31.104582Z","iopub.execute_input":"2024-10-20T22:14:31.104934Z","iopub.status.idle":"2024-10-20T22:14:33.781224Z","shell.execute_reply.started":"2024-10-20T22:14:31.104892Z","shell.execute_reply":"2024-10-20T22:14:33.780361Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"data.shape#, test_data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:14:33.782641Z","iopub.execute_input":"2024-10-20T22:14:33.783388Z","iopub.status.idle":"2024-10-20T22:14:33.789567Z","shell.execute_reply.started":"2024-10-20T22:14:33.783340Z","shell.execute_reply":"2024-10-20T22:14:33.788619Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(6201, 135168)"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"pca = PCA()\n\npca.fit(data)\n\nexplained_variance = pca.explained_variance_ratio_\n\ncumulative_variance = np.cumsum(explained_variance)\n\nn_components_95 = np.argmax(cumulative_variance >= 0.95) + 1\n\nprint(f'95% 분산을 설명하는 n_components: {n_components_95}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T22:14:33.790849Z","iopub.execute_input":"2024-10-20T22:14:33.791532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_components_95","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pca = PCA(n_components = 465)\npca = pca.fit(data)\ndata_pca = pca.transform(data)\n# test_data_pca = pca.transform(test_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_pca.shape, test_data_pca.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T14:16:53.332248Z","iopub.execute_input":"2024-10-20T14:16:53.332699Z","iopub.status.idle":"2024-10-20T14:16:53.340160Z","shell.execute_reply.started":"2024-10-20T14:16:53.332658Z","shell.execute_reply":"2024-10-20T14:16:53.339049Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"((874, 465), (2546, 465))"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"def train_epoch(model, dataloader, optimizer, criterion, scheduler, epoch, device, scorer):\n    dataset_size = 0\n    running_loss = 0.0\n    running_score = 0.0\n    train_loss = []\n    bar = tqdm(enumerate(dataloader), desc='Training', total=len(dataloader), leave=False)\n    model.train()\n    \n    for step, batch in bar:\n        optimizer.zero_grad()\n        \n        data, target = batch\n        data = data.float()#.to('cuda')\n        target = target.long()#.to('cuda')\n        \n        output = model(data)\n        \n        loss = criterion(output, target)\n        \n        loss.backward()\n        optimizer.step()\n\n        train_loss.append(loss.item())\n        \n        preds = torch.argmax(output, dim=1)\n        \n        output_np = preds.detach().cpu().numpy()\n        target_np = target.detach().cpu().numpy()\n        \n        score = multiclass_f1_score(target.cpu(), preds.cpu(), average='macro', num_classes=26)\n        \n        running_loss += loss.item()\n        running_score += score\n        \n        epoch_loss = running_loss / (step + 1)\n        epoch_score = running_score / (step + 1)\n        \n        bar.set_postfix(Train_loss=epoch_loss, Train_score=epoch_score)\n        \n    return epoch_loss, epoch_score, model","metadata":{"execution":{"iopub.status.busy":"2024-10-20T14:16:58.470165Z","iopub.execute_input":"2024-10-20T14:16:58.470718Z","iopub.status.idle":"2024-10-20T14:16:58.481094Z","shell.execute_reply.started":"2024-10-20T14:16:58.470665Z","shell.execute_reply":"2024-10-20T14:16:58.480010Z"},"trusted":true},"outputs":[],"execution_count":53},{"cell_type":"code","source":"def val_epoch(model, dataloader, criterion, device, scorer):\n    outputs = []\n    targets = []\n    running_loss = 0.0\n    bar = tqdm(dataloader, desc='Validating', total=len(dataloader), leave=False)\n    model.eval()\n    \n    with torch.no_grad():\n        for batch in bar:\n            data, target = batch\n            data = data.float()#.to('cuda')\n            target = target.long()#.to('cuda')\n            \n            output = model(data).squeeze()\n            \n            loss = criterion(output, target)\n            \n            predicted = torch.argmax(output, dim=1)\n            \n            outputs.append(predicted.detach().cpu())\n            targets.append(target.detach().cpu())\n            \n            running_loss += loss.item()\n    \n    outputs = torch.cat(outputs)\n    targets = torch.cat(targets)\n    \n    outputs_np = outputs.numpy()\n    targets_np = targets.numpy()\n    val_score = multiclass_f1_score(targets.cpu(), outputs.cpu(), average='macro', num_classes=26)\n    \n    epoch_loss = running_loss / len(dataloader)\n    \n    return epoch_loss, val_score","metadata":{"execution":{"iopub.status.busy":"2024-10-20T14:16:58.804877Z","iopub.execute_input":"2024-10-20T14:16:58.805757Z","iopub.status.idle":"2024-10-20T14:16:58.818937Z","shell.execute_reply.started":"2024-10-20T14:16:58.805707Z","shell.execute_reply":"2024-10-20T14:16:58.817849Z"},"trusted":true},"outputs":[],"execution_count":54},{"cell_type":"code","source":"val_scores = []\ntest_preds = []\n\nreshaped_labels = labels_one_hot\n# major_class_labels = reshaped_labels.argmax(axis=1)\n\nsplitter = MultilabelStratifiedKFold(n_splits = 5, shuffle = True, random_state = CFG['SEED'])\n# splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=CFG['SEED'])\n\nfor fold_idx, (train_index, val_index) in enumerate(splitter.split(data_pca, reshaped_labels)):\n    \n    print(f'Training fold {fold_idx + 1}...')\n    \n    train_data, val_data = data_pca[train_index], data_pca[val_index]\n    train_labels, val_labels = labels[train_index], labels[val_index]\n\n    model = XGBClassifier(tree_method='gpu_hist', gpu_id=0, random_state = CFG['SEED'])\n    # model = lgb.LGBMClassifier(boosting_type = 'gbdt', verbose = -1, device = 'gpu', gpu_platform_id = 0, gpu_device_id = 0)\n    model.fit(train_data, train_labels) # , callbacks = [lgb.early_stopping(stopping_rounds = 20)], eval_set = [(val_data, val_labels)]\n\n    val_pred = model.predict_proba(val_data)\n    # test_pred = model.predict_proba(test_data_pca)\n\n    val_pred = val_pred.argmax(axis = 1)\n    # test_pred = test_pred.argmax(axis = 1)\n\n    val_score = f1_score(val_labels, val_pred, average='macro')\n\n    val_scores.append(val_score)\n    # test_preds.append(test_pred)\n\nprint(f'Validation F1 Scores for each fold: {val_scores}')\nprint(f'Validation F1 Scores for mean: {np.mean(val_scores)}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_data, val_data, train_labels, val_labels = train_test_split(data_pca, major_class_labels, test_size=0.2, stratify=major_class_labels, random_state=42)\n\n# model = lgb.LGBMClassifier(boosting_type = 'gbdt', verbose = -1, device = 'gpu', gpu_platform_id = 0, gpu_device_id = 0)\n# model.fit(train_data, train_labels) # , callbacks = [lgb.early_stopping(stopping_rounds = 20)], eval_set = [(val_data, val_labels)]\n\n# val_pred = model.predict_proba(val_data)\n\n# val_pred = val_pred.argmax(axis = 1)\n\n# val_score = f1_score(val_labels, val_pred, average='macro')\n\n# print(f'Validation F1 Scores: {val_score}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T14:45:33.162315Z","iopub.execute_input":"2024-10-20T14:45:33.162696Z","iopub.status.idle":"2024-10-20T14:45:33.167460Z","shell.execute_reply.started":"2024-10-20T14:45:33.162657Z","shell.execute_reply":"2024-10-20T14:45:33.166426Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"le_encoder.inverse_transform(test_preds[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T14:45:33.169099Z","iopub.execute_input":"2024-10-20T14:45:33.169824Z","iopub.status.idle":"2024-10-20T14:45:33.185527Z","shell.execute_reply.started":"2024-10-20T14:45:33.169785Z","shell.execute_reply":"2024-10-20T14:45:33.184513Z"}},"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"array(['KIPAN', 'STES', 'PRAD', ..., 'BLCA', 'LAML', 'LAML'], dtype=object)"},"metadata":{}}],"execution_count":100},{"cell_type":"code","source":"sample_submission['SUBCLASS'] = le_encoder.inverse_transform(test_preds[0])\nsample_submission.to_csv('xg_submission.csv', encoding='UTF-8-sig', index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T14:45:39.547941Z","iopub.execute_input":"2024-10-20T14:45:39.548676Z","iopub.status.idle":"2024-10-20T14:45:39.563629Z","shell.execute_reply.started":"2024-10-20T14:45:39.548627Z","shell.execute_reply":"2024-10-20T14:45:39.562648Z"}},"outputs":[],"execution_count":101},{"cell_type":"code","source":"val_scores = []\nnum_epochs = 10\n\nreshaped_sequences = train_padded_sequences.mean(dim=2).cpu().numpy()\nreshaped_labels = labels_one_hot\nmajor_class_labels = reshaped_labels.argmax(axis=1)\n\nsplitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor fold_idx, (train_index, val_index) in enumerate(splitter.split(reshaped_sequences, major_class_labels)):\n    train_data, val_data = train_padded_sequences[train_index], train_padded_sequences[val_index]\n    train_labels, val_labels = labels[train_index], labels[val_index]\n\n    train_dataset = TensorDataset(train_data, train_labels)\n    val_dataset = TensorDataset(val_data, val_labels)\n\n    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n    \n    print(f'Training fold {fold_idx + 1}...')\n    \n    patience = 5\n    early_stopping_counter = 0\n    \n    vocab_size = 28\n    emb_dim = 128\n    sequence_length = 126\n    num_classes = 26\n    hidden_dim = 128\n    dropout = 0.5\n    \n    # model = CNN_RNN_Model(num_filters=64, kernel_size=3, hidden_dim=128, output_dim=26)#.to(device)\n    model = CNN_RNN_Model(num_filters = 50, kernel_size = 3, pooling_size = 2, hidden_dim = 128, output_dim = 26, num_layers = 1, dropout = 0.5).to('cuda')\n    \n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n    # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n    # scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)\n    scorer = MulticlassF1Score(average='macro', num_classes=num_classes)\n    \n    for epoch in tqdm(range(1, num_epochs + 1), desc = 'Epoc'):\n        print(time.ctime(), f'Fold {fold_idx + 1}, Epoch {epoch}')\n        \n        train_loss, train_score, model = train_epoch(model, train_loader, optimizer, criterion, scheduler, device, epoch, scorer)\n        \n        val_loss, val_score = val_epoch(model, val_loader, criterion, device, scorer)\n        \n        tqdm.write(f'Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val score: {val_score:.4f}')\n        val_scores.append(val_score)\n        \n        if epoch == 1:\n            best_loss = val_loss\n            best_score = val_score\n            \n            try:\n                torch.save(model.state_dict(), f'best_fold_{fold_idx + 1}.pth')\n                print(f'Model saved for fold {fold_idx + 1}')\n                \n            except Exception as e:\n                print(f'Error saving model for fold {fold_idx + 1}: {e}')\n                \n        if scheduler is not None:\n            scheduler.step(val_loss)\n            \n        if val_loss < best_loss:\n            best_loss = val_loss\n            best_score = val_score\n            early_stopping_counter = 0\n            \n            try:\n                torch.save(model.state_dict(), f'best_fold_{fold_idx + 1}.pth')\n                print(f'Model save for fold {fold_idx + 1}')\n            \n            except Exception as e:\n                print(f'Error saving model for {fold_idx + 1}: {e}')\n            \n        else:\n            early_stopping_counter += 1\n        \n        if early_stopping_counter >= patience:\n            print(f'Early stopping triggered. {best_score: .4f}')\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T06:54:55.195859Z","iopub.execute_input":"2024-10-20T06:54:55.196523Z","iopub.status.idle":"2024-10-20T06:54:56.478650Z","shell.execute_reply.started":"2024-10-20T06:54:55.196484Z","shell.execute_reply":"2024-10-20T06:54:56.475480Z"}},"outputs":[{"name":"stdout","text":"Training fold 1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoc:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59cc6db64d6242a98d5c2f3ee5b52ae1"}},"metadata":{}},{"name":"stdout","text":"Sun Oct 20 06:54:55 2024 Fold 1, Epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6da006320de4fc79cb8c0c6660d49ab"}},"metadata":{}},{"name":"stdout","text":"torch.Size([128, 50, 4230, 37])\ntorch.Size([128, 211500, 37])\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[70], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoc\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39mctime(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m     train_loss, train_score, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     val_loss, val_score \u001b[38;5;241m=\u001b[39m val_epoch(model, val_loader, criterion, device, scorer)\n\u001b[1;32m     49\u001b[0m     tqdm\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[68], line 16\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, optimizer, criterion, scheduler, epoch, device, scorer)\u001b[0m\n\u001b[1;32m     13\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[64], line 74\u001b[0m, in \u001b[0;36mCNN_RNN_Model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# x = x.permute(0, 2, 1)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# x = x.view(batch_size, sequence_length, -1)\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m x \u001b[38;5;241m=\u001b[39m output[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m     77\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:592\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN_TANH\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 592\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn_tanh\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    596\u001b[0m         result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mrnn_relu(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    597\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m    598\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 12.91 GiB. GPU 0 has a total capacity of 15.89 GiB of which 4.12 GiB is free. Process 2582 has 11.77 GiB memory in use. Of the allocated memory 11.24 GiB is allocated by PyTorch, and 247.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 12.91 GiB. GPU 0 has a total capacity of 15.89 GiB of which 4.12 GiB is free. Process 2582 has 11.77 GiB memory in use. Of the allocated memory 11.24 GiB is allocated by PyTorch, and 247.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":70},{"cell_type":"code","source":"# val_scores = []\n# num_epochs = 10\n\n# mskf = MultilabelStratifiedKFold(n_splits = 2, shuffle = True, random_state = 42)\n# reshaped_sequences = train_padded_sequences.mean(dim=2).cpu().numpy()\n# reshaped_labels = labels_one_hot\n\n# for fold_idx, (train_index, val_index) in enumerate(mskf.split(reshaped_sequences, reshaped_labels)):\n#     train_data, val_data = train_padded_sequences[train_index], train_padded_sequences[val_index]\n#     train_labels, val_labels = labels[train_index], labels[val_index]\n    \n#     train_dataset = TensorDataset(train_data, train_labels)\n#     val_dataset = TensorDataset(val_data, val_labels)\n    \n#     train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n#     val_loader = DataLoader(val_dataset, batch_size = 32, shuffle = False)\n    \n#     print(f'Training fold {fold_idx + 1}...')\n    \n#     patience = 5\n#     early_stopping_counter = 0\n    \n#     vocab_size = 28\n#     emb_dim = 128\n#     dropout = 0.2\n#     hidden_dim = 128\n#     num_classes = 26\n\n#     # model = MutationNet(vocab_size = vocab_size, emb_dim = emb_dim, num_classes = num_classes)\n#     # model = mLSTMModel(vocab_size, emb_dim, 128, num_classes)\n#     # model = CNN_LSTM_Model(128, 26, num_layers = 1)\n#     model = RNNWithConv(162, emb_dim, dropout, hidden_dim, num_classes)\n    \n#     criterion = nn.CrossEntropyLoss()\n#     optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n#     scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n#     scorer = MulticlassF1Score(average='macro', num_classes=26)\n    \n#     for epoch in tqdm(range(1, num_epochs + 1), desc = 'Epoc'):\n#         print(time.ctime(), f'Fold {fold_idx + 1}, Epoch {epoch}')\n        \n#         train_loss, train_score, model = train_epoch(model, train_loader, optimizer, criterion, scheduler, device, epoch, scorer)\n        \n#         val_loss, val_score = val_epoch(model, val_loader, criterion, device, scorer)\n        \n#         tqdm.write(f'Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val score: {val_score:.4f}')\n#         val_scores.append(val_score)\n        \n#         if epoch == 1:\n#             best_loss = val_loss\n#             best_score = val_score\n            \n#             try:\n#                 torch.save(model.state_dict(), f'best_fold_{fold_idx + 1}.pth')\n#                 print(f'Model saved for fold {fold_idx + 1}')\n                \n#             except Exception as e:\n#                 print(f'Error saving model for fold {fold_idx + 1}: {e}')\n                \n#         if scheduler is not None:\n#             scheduler.step(val_loss)\n            \n#         if val_loss < best_loss:\n#             best_loss = val_loss\n#             best_score = val_score\n#             early_stopping_counter = 0\n            \n#             try:\n#                 torch.save(model.state_dict(), f'best_fold_{fold_idx + 1}.pth')\n#                 print(f'Model save for fold {fold_idx + 1}')\n            \n#             except Exception as e:\n#                 print(f'Error saving model for {fold_idx + 1}: {e}')\n            \n#         else:\n#             early_stopping_counter += 1\n        \n#         if early_stopping_counter >= patience:\n#             print(f'Early stopping triggered. {best_score: .4f}')\n#             break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T09:44:45.970233Z","iopub.execute_input":"2024-10-19T09:44:45.971985Z","iopub.status.idle":"2024-10-19T09:44:45.983986Z","shell.execute_reply.started":"2024-10-19T09:44:45.971917Z","shell.execute_reply":"2024-10-19T09:44:45.982244Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}